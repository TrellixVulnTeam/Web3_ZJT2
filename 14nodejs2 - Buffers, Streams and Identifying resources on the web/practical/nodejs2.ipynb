{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node.js 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Buffers\n",
    "\n",
    "A data buffer (or just buffer) is a region of a physical memory storage used to temporarily store data while it is being moved from one place to another. Typically, the data is stored in a buffer as it is retrieved from an input device (such as a microphone) or just before it is sent to an output device (such as speakers). However, a buffer may be used when moving data between processes within a computer. Buffers can be implemented in a fixed memory location in hardwareâ€”or by using a virtual data buffer in software, pointing at a location in the physical memory. A majority of buffers are implemented in software, which typically use the faster RAM to store temporary data, due to the much faster access time compared with hard disk drives. Buffers are typically used when there is a difference between the rate at which data is received and the rate at which it can be processed, or in the case that these rates are variable, for example in a printer spooler or in online video streaming.\n",
    "\n",
    "A buffer often adjusts timing by implementing a queue (or FIFO) algorithm in memory, simultaneously writing data into the queue at one rate and reading it at another rate.\n",
    "\n",
    "You can conceptualize a buffer as an array of integer or floating point numbers of various lengths, or as a binary string. Unlike higher-level data structures like arrays, a buffer is not resizable.\n",
    "\n",
    "It corresponds roughly to:\n",
    "\n",
    "- char* or char[] in C/C++\n",
    "- byte[] in Java\n",
    "- A mutable bytes or a non-resizable bytearray in Python\n",
    "- Strings in php if they were mutable\n",
    "\n",
    "## Buffer class in node.js\n",
    "\n",
    "Pure JavaScript is Unicode friendly, but it is not so for binary data. When programmatically interfacing with TCP streams or the file system, it's often necessary to handle octet (byte) streams (i.e. binary streams). Node provides the `Buffer` class which provides instances to store raw binary data similar to an array of integers but corresponds to a raw memory allocation outside the V8 heap. The `Buffer` class is a global class in `node.js` that can be accessed in an application without importing the buffer module.\n",
    "\n",
    "There are 3 different ways of creating a Buffer instance in `node.js`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var buffer1 = new Buffer(10);\n",
    "var buffer2 = new Buffer([10, 20, 30, 40, 50]);\n",
    "var buffer3 = new Buffer(\"Otago Polytechnic\", \"utf-8\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though \"utf8\" is the default encoding, you can use any of the following encodings \"ascii\", \"utf8\", \"utf16le\", \"ucs2\", \"base64\" or \"hex\".\n",
    "\n",
    "Writing to buffers is relatively straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer1.write(\"abcdef\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for reading from a buffer you need to specify the encoding to use as well as the beginning index to start reading and the end index to and reading :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer1.toString('ascii',0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buffers can also be easily converted to a JSON data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ type: 'Buffer',\n",
       "  data: [ 97, 98, 99, 100, 101, 102, 0, 0, 136, 238 ] }"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer1.toJSON()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The file system\n",
    "\n",
    "One of the main differences between client-side JavaScript analogy and `node.js` is that `node.js` allows us to interact with the file system.\n",
    "\n",
    "The `fs` module can be used to list files and directories, create files and directories, stream files, write files, read files, modify file permissions or just about anything that you need to be able to do with the file system.\n",
    "\n",
    "We have already seen how to read directories and files, but let's recap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var fs = require(\"fs\");\n",
    "\n",
    "//reading the content of current folder\n",
    "fs.readdir('./', function(err, files) {\n",
    "\n",
    "    if (err) {\n",
    "        throw err;\n",
    "    }\n",
    "\n",
    "    console.log(files);\n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am the content of file input.txt\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "\n",
    "// reading the content of file named 'input.txt'\n",
    "fs.readFile('./input.txt', \"UTF-8\", function(err, contents) {\n",
    "\n",
    "    console.log(contents);\n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature of the file system module is the ability to create new files, to write text or binary content to those files, or to append text or binary content to an existing file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Created\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "\n",
    "var md = `\n",
    "\n",
    "Sample Markdown Title\n",
    "=====================\n",
    "\n",
    "Sample subtitle\n",
    "----------------\n",
    "\n",
    "* point\n",
    "* point\n",
    "* point\n",
    "\n",
    "`;\n",
    "\n",
    "fs.writeFile(\"sample.md\", md.trim(), function(err) {\n",
    "\n",
    "    console.log(\"File Created\");\n",
    "\n",
    "});\n",
    "\n",
    "fs.appendFile(\"sample.md\", \"\\n\\noops, I forgot something\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the FS module also gives us tools for creating directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Created\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "fs.mkdir(\"lib\", function(err) {\n",
    "\n",
    "    if (err) {\n",
    "        console.log(err);\n",
    "    } else {\n",
    "        console.log(\"Directory Created\");\n",
    "    }\n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing directories is also trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lib directory removed\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "fs.rmdir(\"./lib\", function(err) {\n",
    "\n",
    "    if (err) {\n",
    "        throw err;\n",
    "    }\n",
    "\n",
    "    console.log(\"lib directory removed\");\n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to move, rename, or remove a file, and the fs module has methods for that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.md renamed/moved successfully\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "\n",
    "//the rename method can be used both for renaming a file or for moving it to a different location\n",
    "fs.rename(\"./sample.md\", \"./sample2.md\", function(err) {\n",
    "\n",
    "    if (err) {\n",
    "        console.log(err);\n",
    "    } else {\n",
    "        console.log(\"sample.md renamed/moved successfully\");\n",
    "    }\n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample2.md removed\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "fs.unlink(\"sample2.md\", function(err) {\n",
    "\n",
    "    if (err) {\n",
    "        console.log(err);\n",
    "    } else {\n",
    "        console.log(\"sample2.md removed\");\n",
    "    }\n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streams\n",
    "\n",
    "Streams give us a way to asynchronously handle continuous data flows. Understanding how streams work will dramatically improve the way your application handles large data. Streams in `Node.js` are implementations of the underlying abstract Streams interface and we've already been using them because process standard input and process standard output both implement the Stream interface.\n",
    "\n",
    "Simply put, a stream is nothing but an EventEmitter and implements some specials methods. Depending on the methods implemented, a stream becomes readable, like stdin, writeable like standard output, or duplex, which means they are both readable and writeable. Streams can work with binary data or data encoded in a text format like UTF-8. \n",
    "\n",
    "### Readable streams\n",
    "\n",
    "To illustrate the usefulness of the streams, let's think about a program that needs to read a **very, very** looooooong text file. the problem with a traditional approach, is that the `readFile` method will wait until the entire file is read before invoking the callback function and passing the file contents. This is fine for small and medium-size files but not optimal for very large files. Such an approach will buffer the entire file in one variable, requiring tones of memory and also creating inappropriate latency in the application. With a stream, as opposed to waiting for the entire file to be read, we can use the stream to start receiving small chunks of data from the file as it is being read. This could be very useful to stream or video files for instance. Let's see how to implement a readable stream in `node.js`.\n",
    "\n",
    "First, let's illustrate reading a not so big file (6 MB) using the traditional approach of reading the entire content in a single buffer and waiting for the file reading to complete before handling controll to the callback function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "\n",
    "// reading the entire content of longTextFile.txt will take a few seconds\n",
    "fs.readFile('./longTextFile.txt', \"UTF-8\", function(err, contents) {\n",
    "\n",
    "    console.log(\"Done!\");\n",
    "    /*We can console.log the content in case we want to print out the contents of the file, which I don't \n",
    "    recommend because it is an entire book\n",
    "    and it will take the console  a while to print it all out\n",
    "    */\n",
    "    //console.log(contents); \n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, let's read the content of the file using a readable stream and handling the data chunk by chunk. Obviously, for a file that it's only 6 MB in size, the streaming approach does not make a lot of sense. But for very large files (>1GB) it could be very useful. Node.js streams are event emitters so you can listen to its events to monitor the data being transmitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReadStream {\n",
       "  _readableState: \n",
       "   ReadableState {\n",
       "     objectMode: false,\n",
       "     highWaterMark: 65536,\n",
       "     buffer: BufferList { head: null, tail: null, length: 0 },\n",
       "     length: 0,\n",
       "     pipes: null,\n",
       "     pipesCount: 0,\n",
       "     flowing: true,\n",
       "     ended: false,\n",
       "     endEmitted: false,\n",
       "     reading: false,\n",
       "     sync: true,\n",
       "     needReadable: false,\n",
       "     emittedReadable: false,\n",
       "     readableListening: false,\n",
       "     resumeScheduled: true,\n",
       "     defaultEncoding: 'utf8',\n",
       "     ranOut: false,\n",
       "     awaitDrain: 0,\n",
       "     readingMore: false,\n",
       "     decoder: \n",
       "      StringDecoder {\n",
       "        encoding: 'utf8',\n",
       "        fillLast: [Function: utf8FillLast],\n",
       "        lastNeed: 0,\n",
       "        lastTotal: 0,\n",
       "        lastChar: <Buffer af 0a 00 00> },\n",
       "     encoding: 'UTF-8' },\n",
       "  readable: true,\n",
       "  domain: null,\n",
       "  _events: \n",
       "   { end: [ [Function], [Function] ],\n",
       "     data: [ [Object], [Function] ] },\n",
       "  _eventsCount: 2,\n",
       "  _maxListeners: undefined,\n",
       "  path: './longTextFile.txt',\n",
       "  fd: null,\n",
       "  flags: 'r',\n",
       "  mode: 438,\n",
       "  start: undefined,\n",
       "  end: undefined,\n",
       "  autoClose: true,\n",
       "  pos: undefined,\n",
       "  bytesRead: 0 }"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Started Reading File\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 65536 |  chunk: 602 |\n",
      "\n",
      "\n",
      "\n",
      "Finished Reading File 6488666\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "\n",
    "var stream = fs.createReadStream(\"./longTextFile.txt\", \"UTF-8\");\n",
    "\n",
    "var data = \"\";\n",
    "\n",
    "//this method executes only on the 1st data event\n",
    "stream.once(\"data\", function() {\n",
    "    console.log(\"\\n\\n\\n\");\n",
    "    console.log(\"Started Reading File\");\n",
    "    console.log(\"\\n\\n\\n\");\n",
    "});\n",
    "\n",
    "stream.on(\"data\", function(chunk) {\n",
    "    process.stdout.write(`  chunk: ${chunk.length} |`);\n",
    "    data += chunk;\n",
    "    //console.log(chunk); //in case we want to print out the contents of the chunk\n",
    "}); \n",
    "\n",
    "stream.on(\"end\", function() {\n",
    "    console.log(\"\\n\\n\\n\");\n",
    "    console.log(`Finished Reading File ${data.length}`);\n",
    "    //console.log(data); //in case we want to print out the contents of the file\n",
    "    console.log(\"\\n\\n\\n\");\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writable streams\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other side of the stream coin we have writable streams. The writable stream is used to write the data chunks that are going to be read by the readable streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program Ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write completed.\n"
     ]
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "var data = 'This is some data to be written into a writable Stream';\n",
    "\n",
    "// Create a writable stream\n",
    "var writerStream = fs.createWriteStream('output.txt');\n",
    "\n",
    "// Write the data to stream with encoding to be utf8\n",
    "writerStream.write(data,'UTF8');\n",
    "\n",
    "// Mark the end of file\n",
    "writerStream.end();\n",
    "\n",
    "// Handle stream events --> finish, and error\n",
    "writerStream.on('finish', function() {\n",
    "    console.log(\"Write completed.\");\n",
    "});\n",
    "\n",
    "writerStream.on('error', function(err){\n",
    "   console.log(err.stack);\n",
    "});\n",
    "\n",
    "console.log(\"Program Ended\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piping streams\n",
    "\n",
    "Piping is a mechanism where we provide the output of one stream as the input to another stream. It is normally used to get data from one stream and to pass the output of that stream to another stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program Ended\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var fs = require(\"fs\");\n",
    "\n",
    "// Create a readable stream\n",
    "var readerStream = fs.createReadStream('input.txt');\n",
    "\n",
    "// Create a writable stream\n",
    "var writerStream = fs.createWriteStream('output.txt');\n",
    "\n",
    "// Pipe the read and write operations\n",
    "// read input.txt and write data to output.txt\n",
    "readerStream.pipe(writerStream);\n",
    "\n",
    "console.log(\"Program Ended\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Create a script that appends a string to a non-empty text file.\n",
    "2. This exercise requires you to do a bit of research on the `node.js` `crypto` module. Use a `readStream` to read the content of a text file and create a SHA1 digest of the file contents and output the SHA1 digest to the terminal.\n",
    "3. Create a program that creates 2 buffers and compares their content. If both buffers are equal, your program should concatenate the buffers, otherwise do nothing."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "6.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
